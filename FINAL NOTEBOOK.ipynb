{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b66300a",
   "metadata": {},
   "source": [
    "# EDSA 2201 & 2207 classification hackathon \n",
    "\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**Elelwani Tshikovhi**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract\n",
    "\n",
    "### Hackathon Overview: South African Language Identification Hack 2022\n",
    "\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "From South African Government\n",
    "\n",
    "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2205222%2F7f34544c1b1f61d1a5949bddacfd84a9%2FSouth_Africa_languages_2011.jpg?generation=1604393669339034&alt=media\" width=80%/>\n",
    "\n",
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "\n",
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in using various classification models.\n",
    "\n",
    "### Data overview\n",
    "The dataset used for this challenge is the NCHLT Text Corpora collected by the South African Department of Arts and Culture & Centre for Text Technology (CTexT, North-West University, South Africa). The training set was improved through additional cleaning done by Praekelt.\n",
    "\n",
    "The data is in the form Language ID, Text. The text is in various states of cleanliness. Some NLP techniques will be necessary to clean up the data.\n",
    "File descriptions\n",
    "\n",
    "- train_set.csv - the training set\n",
    "- test_set.csv - the test set\n",
    "- sample_submission.csv - a sample submission file in the correct format\n",
    "\n",
    "Language IDs\n",
    "\n",
    "- afr - Afrikaans\n",
    "- eng - English\n",
    "- nbl - isiNdebele\n",
    "- nso - Sepedi\n",
    "- sot - Sesotho\n",
    "- ssw - siSwati\n",
    "- tsn - Setswana\n",
    "- tso - Xitsonga\n",
    "- ven - Tshivenda\n",
    "- xho - isiXhosa\n",
    "- zul - isiZulu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5cf23a",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Data Engineering</a>\n",
    "\n",
    "<a href=#four>4. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191028a",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "|  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdc01e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: advertools in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from advertools) (0.4.8)\n",
      "Requirement already satisfied: scrapy in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from advertools) (2.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from advertools) (1.4.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from advertools) (7.0.0)\n",
      "Requirement already satisfied: twython in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from advertools) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from pandas->advertools) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from pandas->advertools) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from pandas->advertools) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->advertools) (1.16.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.0.4)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (0.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (58.0.4)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.1.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.6.2)\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (4.6.3)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.22.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (21.0.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (2.0.5)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (5.4.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (3.4.8)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (21.1.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (0.6.0)\n",
      "Requirement already satisfied: tldextract in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (3.3.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.6.0)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from scrapy->advertools) (22.4.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy->advertools) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.0->scrapy->advertools) (2.20)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy->advertools) (1.0.1)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->advertools) (0.2.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->advertools) (21.2.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (1.0.2)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (21.0.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (21.3.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (20.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (3.10.0.2)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy->advertools) (3.2)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from tldextract->scrapy->advertools) (3.3.1)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from tldextract->scrapy->advertools) (2.26.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from tldextract->scrapy->advertools) (1.5.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (2021.10.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from twython->advertools) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.4.0->twython->advertools) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install advertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0782eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\f5468981\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\f5468981\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data analysis and wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Preprocessing\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import advertools as adv\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import  log_loss\n",
    "import time\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# Libraries to Save/Restore Models\n",
    "import pickle\n",
    "# Downloads\n",
    "nltk.download(['punkt','stopwords'])\n",
    "%matplotlib inline\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c82d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: six in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (3.4.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (0.20)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from catboost) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\f5468981\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660a9cb",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac2203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train = pd.read_csv('train_set.csv')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a66d4",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "|This phase is important. This will help to understand patterns in the data, pinpoint any outliers and indicate relationships between variables using  descriptive statistics and data visualisations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b1af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsn</td>\n",
       "      <td>kgetse nngwe le nngwe e e sa faposiwang mo tsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ven</td>\n",
       "      <td>mbadelo dze dza laelwa dzi do kwama mahatulele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nso</td>\n",
       "      <td>maloko a dikhuduthamaga a ikarabela mongwe le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5     nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "6     tsn  kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
       "7     ven  mbadelo dze dza laelwa dzi do kwama mahatulele...\n",
       "8     nso  maloko a dikhuduthamaga a ikarabela mongwe le ...\n",
       "9     tsn  fa le dirisiwa lebone le tshwanetse go bontsha..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view the first 10 rows of the train data\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e08c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ke feela dilense tše hlakilego, tša pono e tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;fn&gt;(762010101403 AM) 1495 Final Gems Birthing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>So, on occasion, are statistics misused.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta.\n",
       "5      6  Ke feela dilense tše hlakilego, tša pono e tee...\n",
       "6      7  <fn>(762010101403 AM) 1495 Final Gems Birthing...\n",
       "7      8  Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...\n",
       "8      9  u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...\n",
       "9     10           So, on occasion, are statistics misused."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view the first 10 rows of the test data\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68bbbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n",
      "information of TRAIN dataset: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n",
      "informationof TEST dataaet: None\n"
     ]
    }
   ],
   "source": [
    "# view the info for both data set.\n",
    "print(f'information of TRAIN dataset: {train.info()}')\n",
    "print(f'informationof TEST dataaet: {test.info()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07388ef6",
   "metadata": {},
   "source": [
    "- Train data has two categorical colums and test data has 1 categorical data \n",
    "- No missing values for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7447b3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6874f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2501c9a",
   "metadata": {},
   "source": [
    "### Further exploratory of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed0121bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6304a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fc86b",
   "metadata": {},
   "source": [
    "insight  = `No Missing Values in the Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc741156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distributin of each language \n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='lang_id',data=train, palette=\"autumn\")\n",
    "plt.title('Count of lang_id\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09fcb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xho    3000\n",
       "eng    3000\n",
       "nso    3000\n",
       "ven    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "tso    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of observations per lan_id\n",
    "train.lang_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd02dd9",
   "metadata": {},
   "source": [
    "All language ideas have same number which akes it a well balanced data  for each language class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1315b9",
   "metadata": {},
   "source": [
    "unique Language IDs\n",
    "\n",
    "- afr - Afrikaans\n",
    "- eng - English\n",
    "- nbl - isiNdebele\n",
    "- nso - Sepedi\n",
    "- sot - Sesotho\n",
    "- ssw - siSwati\n",
    "- tsn - Setswana\n",
    "- tso - Xitsonga\n",
    "- ven - Tshivenda\n",
    "- xho - isiXhosa\n",
    "- zul - isiZulu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73076dd1",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data cleaning\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data Cleaning ⚡ |\n",
    "| :--------------------------- |\n",
    "|  clean the dataset, and possibly create new features -using Natural language process . |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c5b11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lang_id', 'text'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebdb9d",
   "metadata": {},
   "source": [
    "# 4.1 Cleaning the data \n",
    "Removing the noise in the data sets  such as punctuation and numbers  making the data more clean "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f8cfd",
   "metadata": {},
   "source": [
    "Cleaning the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57043525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00631c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulunatal department of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsn</td>\n",
       "      <td>kgetse nngwe le nngwe e e sa faposiwang mo tsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ven</td>\n",
       "      <td>mbadelo dze dza laelwa dzi do kwama mahatulele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nso</td>\n",
       "      <td>maloko a dikhuduthamaga a ikarabela mongwe le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqosiseko wenza amalungiselelo kumaziko axh...\n",
       "1     xho  idha iya kuba nobulumko bokubeka umsebenzi nap...\n",
       "2     eng  the province of kwazulunatal department of tra...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5     nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "6     tsn  kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
       "7     ven  mbadelo dze dza laelwa dzi do kwama mahatulele...\n",
       "8     nso  maloko a dikhuduthamaga a ikarabela mongwe le ...\n",
       "9     tsn  fa le dirisiwa lebone le tshwanetse go bontsha..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data cleaning for train data\n",
    "#removing tags \n",
    "to_remove = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});''<.*?>')\n",
    "#function to remove the tags\n",
    "def cleantags(lang):\n",
    "  cleanlang = re.sub(to_remove, '', lang)\n",
    "  return cleanlang\n",
    "df['text'] = df['text'].apply(cleantags)\n",
    "\n",
    "#Remove punctuation\n",
    "def remove_punctuation(lang):\n",
    "  stringpunct = string.punctuation \n",
    "  return ''.join([l for l in lang if l not in stringpunct])\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n",
    "\n",
    "#removing newline space\n",
    "def cleantext(text):\n",
    "  text =re.sub(\"\\n\",\" \",text)\n",
    "  text = re.sub(r'\\d+','',text)\n",
    "  text = re.sub(r'[@][©®™]','',text)\n",
    "  return text\n",
    "df['text'] = df['text'].apply(cleantext)\n",
    "\n",
    "# Make lower case\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa45856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placing some short words\n",
    "#df['text'] =df['text'].str.replace(\".txt\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c800bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing short words from train data\n",
    "#df['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23bd10",
   "metadata": {},
   "source": [
    "# Cleaning the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96a0a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ke feela dilense tše hlakilego, tša pono e tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;fn&gt;(762010101403 AM) 1495 Final Gems Birthing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>So, on occasion, are statistics misused.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta.\n",
       "5      6  Ke feela dilense tše hlakilego, tša pono e tee...\n",
       "6      7  <fn>(762010101403 AM) 1495 Final Gems Birthing...\n",
       "7      8  Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...\n",
       "8      9  u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...\n",
       "9     10           So, on occasion, are statistics misused."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data before being cleaned\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95bf767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#made a copy so not to interfere with the original data\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32da13df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowering case...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mmasepala fa maemo a a kgethegileng a letlelel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ke feela dilense tše hlakilego tša pono e tee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>am  final gems birthing optionszulutxt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>ntjhafatso ya konteraka ya mosebetsi etsa bonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ugems uhlinzeka ngezinzuzo zemithi yezifo ezin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>so on occasion are statistics misused</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  mmasepala fa maemo a a kgethegileng a letlelel...\n",
       "1      2  uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3          tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3      4  kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                       winste op buitelandse valuta\n",
       "5      6  ke feela dilense tše hlakilego tša pono e tee ...\n",
       "6      7             am  final gems birthing optionszulutxt\n",
       "7      8  ntjhafatso ya konteraka ya mosebetsi etsa bonn...\n",
       "8      9  ugems uhlinzeka ngezinzuzo zemithi yezifo ezin...\n",
       "9     10              so on occasion are statistics misused"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaning for train data\n",
    "#removing tags\n",
    "to_remove = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});''<.*?>')\n",
    "#function to remove the tags\n",
    "def cleantags(lang):\n",
    "  cleanlang = re.sub(to_remove, '', lang)\n",
    "  return cleanlang\n",
    "df_test['text'] = df_test['text'].apply(cleantags)\n",
    "\n",
    "#Remove punctuation\n",
    "import string\n",
    "def remove_punctuation(lang):\n",
    "  stringpunct = string.punctuation\n",
    "  return ''.join([l for l in lang if l not in stringpunct])\n",
    "df_test['text'] =df_test['text'].apply(remove_punctuation)\n",
    "\n",
    "#removing newline space\n",
    "def cleantext(text):\n",
    "  text =re.sub(\"\\n\",\" \",text)\n",
    "  text = re.sub(r'\\d+','',text)\n",
    "  text = re.sub(r'[@][©®™]','',text)\n",
    "  return text\n",
    "df_test['text'] = df_test['text'].apply(cleantext)\n",
    "\n",
    "# Make lower case\n",
    "print ('Lowering case...')\n",
    "df_test['text'] = df_test['text'].str.lower()\n",
    "\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5092d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placing some short words\n",
    "#df_test['text'] =df_test['text'].str.replace(\".txt\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b36aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing short words from train data\n",
    "#df_test['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce023f23",
   "metadata": {},
   "source": [
    "## insight\n",
    "- Some languages had english text on them and even short english words eg `txt`  it would have  made sense to remove some english words from those other non english languages but it proof to be a difficult task  deep learning would help in this situation\n",
    "-  in some languages punctuation matter the words can lose meaning and sotho and pedi can have similar words making predictions more complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1079c09",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, create one or more regression models that are able to accurately predict the Sentiment. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400c932",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75c52be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the features and the target\n",
    "x = df['text']\n",
    "y = df['lang_id']\n",
    "\n",
    "# two vectoriser to use  which one to chose\n",
    "#cv = CountVectorizer(min_df = 1,max_df = 0.9, ngram_range =(1,3),stop_words ='english')\n",
    "tfidf = TfidfVectorizer(min_df = 1,max_df = 0.9, ngram_range =(1,2),stop_words ='english')\n",
    "X = tfidf .fit_transform(x)\n",
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78b918",
   "metadata": {},
   "source": [
    "# Building Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d03a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ec16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'Nearest Neighbors','MultinomialNB',\n",
    "         'SGDClassifier','ComplementNB', 'Random Forest', 'Ridge','BernoulliNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa8dc3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(C=10,\n",
    "            max_iter= 1000,\n",
    "            multi_class='ovr',\n",
    "            random_state= 220,\n",
    "            solver= 'saga'),\n",
    "    KNeighborsClassifier(1),\n",
    "    MultinomialNB(alpha = 0.1),\n",
    "    SGDClassifier(loss='hinge',\n",
    "                    penalty='l2',\n",
    "                    alpha=1e-3,\n",
    "                    random_state=42,\n",
    "                    max_iter=1000),\n",
    "    ComplementNB(),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    RidgeClassifier(alpha = 0.1),\n",
    "    BernoulliNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc546f4",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9475a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Nearest Neighbors model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting MultinomialNB model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting SGDClassifier model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting ComplementNB model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Random Forest model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Ridge model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting BernoulliNB model...\n",
      "... predicting\n",
      "... scoring\n",
      "... ALL models done running \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred,)\n",
    "    precision = metrics.precision_score(y_train, y_pred,average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred,average=\"weighted\")\n",
    "\n",
    "    f1        = metrics.f1_score(y_train, y_pred,average=\"weighted\")\n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test,average=\"weighted\")\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf\n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)\n",
    "\n",
    "print ('... ALL models done running ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09191d2",
   "metadata": {},
   "source": [
    "##  Model perfomance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98204aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Train</th>\n",
       "      <th>F1 Test</th>\n",
       "      <th>Train Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>69.978721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938460</td>\n",
       "      <td>0.032495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998484</td>\n",
       "      <td>0.366520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996362</td>\n",
       "      <td>14.507294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.393986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.996356</td>\n",
       "      <td>0.451234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.995522</td>\n",
       "      <td>0.995548</td>\n",
       "      <td>0.995522</td>\n",
       "      <td>0.995520</td>\n",
       "      <td>0.985710</td>\n",
       "      <td>1.796262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.099966</td>\n",
       "      <td>0.916128</td>\n",
       "      <td>0.099966</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>0.181726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1 Train   F1 Test  \\\n",
       "Classifier                                                               \n",
       "Logistic Regression  1.000000   1.000000  1.000000  1.000000  0.995759   \n",
       "Nearest Neighbors    1.000000   1.000000  1.000000  1.000000  0.938460   \n",
       "MultinomialNB        1.000000   1.000000  1.000000  1.000000  0.998484   \n",
       "Ridge                1.000000   1.000000  1.000000  1.000000  0.996362   \n",
       "BernoulliNB          1.000000   1.000000  1.000000  1.000000  0.997285   \n",
       "ComplementNB         0.999966   0.999966  0.999966  0.999966  0.996356   \n",
       "SGDClassifier        0.995522   0.995548  0.995522  0.995520  0.985710   \n",
       "Random Forest        0.099966   0.916128  0.099966  0.030211  0.016888   \n",
       "\n",
       "                     Train Time  \n",
       "Classifier                       \n",
       "Logistic Regression   69.978721  \n",
       "Nearest Neighbors      0.032495  \n",
       "MultinomialNB          0.366520  \n",
       "Ridge                 14.507294  \n",
       "BernoulliNB            0.393986  \n",
       "ComplementNB           0.451234  \n",
       "SGDClassifier          1.796262  \n",
       "Random Forest          0.181726  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('F1 Train', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683852d7",
   "metadata": {},
   "source": [
    "`logistic regresion` and `Nearest neighbors` are  extremely overfitting  worse than `Ridge`,`MultinomialNB`,`ComplementNB`,`BernoulliNB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57752e",
   "metadata": {},
   "source": [
    "### hypertuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e554372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'alpha': 0.3}\n",
      "accuracy 0.996969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      1.00       281\n",
      "         eng       1.00      1.00      1.00       297\n",
      "         nbl       0.99      0.99      0.99       327\n",
      "         nso       1.00      0.99      1.00       322\n",
      "         sot       0.99      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       286\n",
      "         tsn       1.00      1.00      1.00       297\n",
      "         tso       1.00      1.00      1.00       253\n",
      "         ven       1.00      1.00      1.00       322\n",
      "         xho       0.99      1.00      1.00       313\n",
      "         zul       1.00      0.98      0.99       295\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.1, 1, 5,0.3,0.5, 10]}\n",
    "grid = GridSearchCV(ComplementNB(), param_grid=param_grid,cv= 5,scoring = 'f1_weighted')\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"Best parameters:\")\n",
    "lr_params = grid.best_params_\n",
    "print(grid.best_params_)\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29273a",
   "metadata": {},
   "source": [
    "Count vectorizer works better but takes too long to fit such large data set  i used tfidf to vectorize to see which model perform best "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335b701",
   "metadata": {},
   "source": [
    "`Ridge`,`MultinomialNB`,`ComplementNB`,`BernoulliNB` have the highest f1 score and accuracy which we need to hypertumes to maximise predictions since most of the models are overfiting the f1 score here is not same score Kaggle is giving me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d61cbe",
   "metadata": {},
   "source": [
    "# First Stacking  of high models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db7fec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2eecfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992727272727273"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['text']\n",
    "y = df['lang_id']\n",
    "estimators = [('Multinomialnb', MultinomialNB(alpha = 0.1)),('Multinomial', MultinomialNB(alpha = 0.1))]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator = MultinomialNB(alpha = 0.1) )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv1 = CountVectorizer(ngram_range =(1,5),analyzer = \"char\",min_df =1,max_df=0.9)\n",
    "X = cv1.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a81e2",
   "metadata": {},
   "source": [
    "### Second standing that gave me secong highest score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b8efbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996363636363637"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['text']\n",
    "y = df['lang_id']\n",
    "estimators = [('MultinomialNB', MultinomialNB(alpha = 0.1)),('Multinomial', MultinomialNB(alpha = 0.1))]\n",
    "\n",
    "clf1 = StackingClassifier(estimators=estimators, final_estimator = RidgeClassifier(alpha = 0.1) )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv1 = CountVectorizer(ngram_range =(3,7),analyzer = \"char\")\n",
    "X = cv1.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "clf1.fit(X_train, y_train)\n",
    "clf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaacc81",
   "metadata": {},
   "source": [
    "third stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93403a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996363636363637"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['text']\n",
    "y = df['lang_id']\n",
    "estimators = [('MultinomialNB', MultinomialNB(alpha = 0.1)),('Multinomial', MultinomialNB(alpha = 0.1))]\n",
    "\n",
    "clf2 = StackingClassifier(estimators=estimators, final_estimator = RidgeClassifier(alpha = 0.01) )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv1 = CountVectorizer(ngram_range =(3,8),analyzer = \"char\")\n",
    "X = cv1.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3bcf5",
   "metadata": {},
   "source": [
    "#  Choosing the best model for FINAL submission file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc43b3",
   "metadata": {},
   "source": [
    "FINAL STACKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fead028",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df[\"text\"]\n",
    "y = df[\"lang_id\"]\n",
    "cv = CountVectorizer(ngram_range=(6,6), analyzer='char', min_df=2, max_df=0.9, stop_words='english')\n",
    "\n",
    "X = cv.fit_transform(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "\n",
    "                                                    test_size=0.01,\n",
    "\n",
    "                                                    random_state=10)\n",
    "x_test = cv.transform(df_test[\"text\"]) #going to use the test data to test the performance of the test and for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c5513",
   "metadata": {},
   "source": [
    "FITTING FIRST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bc50504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "estimators = [('Complement', ComplementNB(alpha = 0.01)),('Multinomial', MultinomialNB(alpha=0.01))]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator = MultinomialNB(alpha = 0.01) , n_jobs=-1,passthrough=True)\n",
    "clf.fit(X_train, y_train)\n",
    "print (clf.score(X_test, y_test))\n",
    "y_pred1 = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d994b4",
   "metadata": {},
   "source": [
    "SECOND MODELS FOR FINAL STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7d6eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "estimators = [('Complement', ComplementNB(alpha = 0.01)),('Multinomial', MultinomialNB(alpha=0.02))]\n",
    "\n",
    "clf2 = StackingClassifier(estimators=estimators, final_estimator = clf, n_jobs=-1,passthrough=True)\n",
    "clf2.fit(X_train, y_train)\n",
    "print(clf2.score(X_test, y_test))\n",
    "y_pred1 = clf2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51879df6",
   "metadata": {},
   "source": [
    "# CONCLUSION \n",
    "MOst of the models are over fitting after stacking locally im getting 1 while on kaggle i get 0.9753 which is 0.0247 less meaning the models are overfitting by a great margin .Some of the languages we not predicted correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9049a",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 7. Model Documentation and Submission file\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model documentation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section it contains submission files and model saving |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e550e2c",
   "metadata": {},
   "source": [
    "general submission file for some models i tried "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76010de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test['index'])\n",
    "test1 = df_test['text'] #using cleaned test text data \n",
    "# vectorise test data\n",
    "test_vec = cv.transform(test1) # replace cv with tfidt if used a different vectorizer\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = clf.predict(test_vec) #replace clf with any model you wanna \n",
    "# Assign a new column of predictions\n",
    "submission_df['lang_id'] = y_pred\n",
    "# save the csv file and submit it. \n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12532619",
   "metadata": {},
   "source": [
    "\n",
    "submission file for final  super stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8313762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test['index'])\n",
    "\n",
    "submission_df['lang_id'] = y_pred1 # predictions generated by stacking \n",
    "\n",
    "submission_df.to_csv('submissionfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1cb8c7",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "## Reference Links\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd9562",
   "metadata": {},
   "source": [
    "Resources that helped me with the challenges\n",
    "- https://www.kaggle.com/datasets/basilb2s/language-detection\n",
    "- edsa buiding classifiers notebook\n",
    "- https://bush-dev.com/introduction-to-stacking-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "04455e36e172f6b292652d16f1e65dd2a7915d80c3850a404294de2c47ba9b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
